# Define função do modelo ARMA(p,q)-GARCH(r,s) (sem intercepto na mÉdia)
# Argumentos da função:
# params: vetor de parametros 
# data: série temporal
# np: ordem AR
# nq: ordem MA
# nr: ordem ARCH
# ns: ordem GARCH
ARMAGARCH <- function(params,data,np,nq,nr,ns,dens) {
  T <- length(data)
  errors <- integer(T)
  sigma2 <- integer(T)
  m <- 1+max(np,nq,nr,ns)
  sigma2[1:m] <- var(data)
  for (t in m:T) {
    # Recursão AR
    errors[t] <- data[t]
    for (i in 1:np) {
      errors[t] <- errors[t] - params[i]*data[t-i]
    }
    # Recursão MA
    for (i in 1:nq) {
      errors[t] <- errors[t] - params[np+i]*errors[t-i]
    }
    # Recursão ARCH
    sigma2[t] <- params[np+nq+1]
    for (i in 1:nr) {
      sigma2[t] <- sigma2[t] + params[np+nq+1+i]*errors[t-i]^2
    }
    # Recursão GARCH
    for (i in 1:ns) {
      sigma2[t] <- sigma2[t] + params[np+nq+nr+1+i]*sigma2[t-i]
    }
    sigma2[t] <- sigma2[t]
  }
  if (dens=="t") {
    v<-params[np+nq+nr+ns+2]
    #verossim <- -(gamma((v+1)/2)/((gamma(v/2))*sqrt(pi*(v-2))*sqrt(sigma2)*(1+(errors^2)/(sigma2*(v-2)))^((v+1)/2)))
    verossim <- -(log(gamma((v+1)/2)/(sqrt((v-2)*pi)*gamma(v/2)))-log(sigma2)/2-((v+1)/2)*log(1+errors^2/(sigma2*(v-2))))
    #verossim <- ((gamma((v+1/2)))/(sqrt(pi)*gamma(v/2))*(v-2)^(-1/2)*(sigma2)^(-1/2)*((1+errors^2/(sigma2*(v-2))))^(-(v+1)/2))
  } else if (dens=="ged") {
    v<-params[np+nq+nr+ns+2]
    #lambda<-sqrt(((2^(-2/v))*gamma(1/v))/gamma(3/v))
    #verossim<- (v*exp(-(1/2)*(abs(errors/(lambda*sqrt(sigma2))))^v)*(1/sqrt(sigma2)))/(lambda*(2^((1+1/v))*gamma(1/v)))
    lnlambda<- -(log(2)/v)+(log(gamma(1/v))/2)-(log(gamma(3/v))/2)
    
    #LOG Kevin Sheppard
    verossim<- (log(v)-((abs(errors/sqrt(sigma2)))^v)/2-lnlambda-((v+1)/v)*log(2)-log(gamma(1/v)))
  
    # LOG http://cims.nyu.edu/~almgren/timeseries/Vol_Forecast1.pdf
    #verossim<- ((log(v)-((abs(data/(exp(lnlambda)*sqrt(sigma2))))^v)/2)-log(sqrt(sigma2))-lnlambda-((1+1/v)*log(2)-log(gamma(1/v))))
    
    # LOG https://editorialexpress.com/cgi-bin/conference/download.cgi?db_name=ACE2005&paper_id=217
    #verossim<- ((log(v)-((abs(errors/exp(lnlambda)))^v) /2-lnlambda-((v+1)/v)*log(2)-log(gamma(1/v))))
  } else if (dens=="PED") {
    #http://epublications.uef.fi/pub/urn_isbn_978-952-219-072-7/urn_isbn_978-952-219-072-7.pdf
    lambda<-params[np+nq+nr+ns+2]
    gam<-params[np+nq+nr+ns+3]
    #verossim<- -((1-gam^2)/(2*gamma(1+1/lambda)*lambda^(1/lambda))*exp(-((abs(data-gam*abs(data))^lambda))/lambda))
    verossim<- -(log(1-gam^2)-log(2)-log(gamma(1+1/lambda))-log(lambda)/lambda-((abs(data-gam*abs(data)))^lambda)/lambda)
    } else {
    verossim <- 0.5*(2*log(sqrt(sigma2)) + log(sigma2) + errors^2/sigma2 + log(2*pi))
  }
  return(list(LLF=sum(verossim),sigma2=sigma2,residuals=errors/sqrt(sigma2)))
}

# Baixa série de preços do S&P 500
# install.packages("BatchGetSymbols")
library(BatchGetSymbols)
library(ggplot2)
my.ticker <- c('^GSPC')
first.date <- Sys.Date()-1500
last.date <- Sys.Date()
l.out <- BatchGetSymbols(tickers = my.ticker,first.date = first.date,last.date = last.date)
returns <- data.frame(retornos=diff(log(l.out$df.tickers$price.adjusted))*100,datas=l.out$df.tickers$ref.date[2:l.out$df.control$total.obs])

# Estima modelo ARMA,(1,1)-GARCH(1,1) - NORMAL
init.params <- c(0.1,0.1,0.1,0.1,0.5)
# Define restrições
ui <- rbind(c(0,0,1,0,0),c(0,0,0,1,0),c(0,0,0,0,1),c(0,0,0,-1,-1))
ci <- c(0,0,0,-1)
ARMAGARCH.optim <- function(params,data,np,nq,nr,ns,dens) {
  ARMAGARCH(params,data,np,nq,nr,ns,dens)$LLF
}
resultados <- constrOptim(init.params,ARMAGARCH.optim,data=returns[,1],np=1,nq=1,nr=1,ns=1,grad=NULL,ui=ui,ci=ci,dens="normal")
options(scipen=999)
print(resultados$par)
resultados.finais.normal <- ARMAGARCH(resultados$par,data=returns[,1],np=1,nq=1,nr=1,ns=1,dens="normal")
df.normal <- data.frame(returns,sigma2=resultados.finais$sigma2,residuals=resultados.finais$residuals)


# Estima modelo ARMA(1,1)-GARCH(1,1) -T de Student
init.params <- c(0.1,0.1,0.1,0.1,0.5,5)
# Define restrições
ui <- rbind(c(0,0,1,0,0,0),c(0,0,0,1,0,0),c(0,0,0,0,1,0),c(0,0,0,-1,-1,0),c(0,0,0,0,0,1),c(0,0,0,0,0,-1))
ci <- c(0,0,0,-1,2+.Machine$double.eps,-30)
ARMAGARCH.optim <- function(params,data,np,nq,nr,ns,dens) {
  ARMAGARCH(params,data,np,nq,nr,ns,dens)$LLF
}
resultados <- constrOptim(init.params,ARMAGARCH.optim,data=returns[,1],np=1,nq=1,nr=1,ns=1,grad=NULL,ui=ui,ci=ci,dens="t")
options(scipen=999)
print(resultados$par)
resultados.finais.t <- ARMAGARCH(resultados$par,data=returns[,1],np=1,nq=1,nr=1,ns=1,dens="t")
df.t <- data.frame(returns,sigma2=resultados.finais.t$sigma2,residuals=resultados.finais.t$residuals)

# Estima modelo ARMA(1,1)-GARCH(1,1) -Generalized Exponential Distribution
#init.params <- c(0.1,0.1,0.1,0.1,0.1,5,5)
# Define restrições
#ui <- rbind(c(0,0,1,0,0,0),c(0,0,0,1,0,0),c(0,0,0,0,1,0),c(0,0,0,-1,-1,0),c(0,0,0,0,0,1))
#ci <- c(0,0,0,-1,1+.Machine$double.eps)
#ARMAGARCH.optim <- function(params,data,np,nq,nr,ns,dens) {
#  ARMAGARCH(params,data,np,nq,nr,ns,dens)$LLF
#}
#resultados <- constrOptim(init.params,ARMAGARCH.optim,data=returns[,1],np=1,nq=1,nr=1,ns=1,grad=NULL,ui=ui,ci=ci,dens="ged")
#options(scipen=999)
#print(resultados$par)

# Estima modelo ARMA(1,1)-GARCH(1,1) -Pòwer Exponential Distribution
init.params <- c(0.1,0.1,0.1,0.1,0.1,3,0.1)
# Define restrições
ui <- rbind(c(0,0,1,0,0,0,0),c(0,0,0,1,0,0,0),c(0,0,0,0,1,0,0),c(0,0,0,-1,-1,0,0))
ci <- c(0,0,0,-1)
ARMAGARCH.optim <- function(params,data,np,nq,nr,ns,dens) {
  ARMAGARCH(params,data,np,nq,nr,ns,dens)$LLF
}
resultados <- constrOptim(init.params,ARMAGARCH.optim,data=returns[,1],np=1,nq=1,nr=1,ns=1,grad=NULL,ui=ui,ci=ci,dens="PED")
options(scipen=999)
print(resultados$par)
resultados.finais.PED <- ARMAGARCH(resultados$par,data=returns[,1],np=1,nq=1,nr=1,ns=1,dens="PED")
df.PED <- data.frame(returns,sigma2=resultados.finais.PED$sigma2,residuals=resultados.finais.PED$residuals)

# Retorna variáveis e avalia qualidade do ajuste

# Faz gráfico 
require(gridExtra)
require(forecast)
require(ggplot2)
p1 <- ggplot(data = returns, aes(x = datas, y = retornos))
p1 <- p1 + geom_line()
p1 <- p1 + labs(x = 'Dates', y = 'Retornos')

p2.normal <- ggplot(data = df.normal, aes(x = datas, y = sqrt(sigma2)))
p2.normal <- p2 + geom_line()
p2.normal <- p2 + labs(x = 'Dates', y = 'Desvio padrão condicional')

p3.normal <- ggAcf(df.normal$residuals^2, main="ACF do quadrado dos resíduos padronizados")

p2.t <- ggplot(data = df.t, aes(x = datas, y = sqrt(sigma2)))
p2.t <- p2 + geom_line()
p2.t <- p2 + labs(x = 'Dates', y = 'Desvio padrão condicional')

p3.t <- ggAcf(df.t$residuals^2, main="ACF do quadrado dos resíduos padronizados")

p2.PED <- ggplot(data = df.PED, aes(x = datas, y = sqrt(sigma2)))
p2.PED <- p2 + geom_line()
p2.PED <- p2 + labs(x = 'Dates', y = 'Desvio padrão condicional')

p3.PED <- ggAcf(df.PED$residuals^2, main="ACF do quadrado dos resíduos padronizados")

grid.arrange(p1, p1, p1, p2.normal, p2.t, p2.PED, p3.normal, p3.t, p3.PED, ncol=3, nrow=3)
  
SQR<-c(sum(df.normal$residuals^2),sum(df.t$residuals^2),sum(df.PED$residuals^2))
